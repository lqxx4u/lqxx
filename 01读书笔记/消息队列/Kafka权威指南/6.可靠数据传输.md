### 6.可靠数据传输
#### 1. 可靠性保证
遵循ACID规范，即支持事务相关行为

    1）.kafka可以保证分区消息的顺序。同一个生产者往同一个分区写入
    2）.只有当消息被写入分区的所有同步副本时才被认为是已提交的。生产者可以选择接收不同类型：比如消息被完全提交时确认、或在消息被写入首领副本时确认、或在消息被发送到网络时确认。
    3）.只要有一个副本是活跃的，已提交消息就不会丢失。
    4）.消费者智能读取已经提交的消息。




#### 2.复制
    Kafka的复制机制和分区的多副本架构是Kafka可靠性保证的核心。
    同步复制条件：
    1）与Zookeeper直接有一个活跃会话，过去6s（可配）内向ZooKeeper发送过心跳
    2）过去10s（可配）内从首领那里获取过消息
    3）过去10s内从首领那里获取过最新的消息。必须是几乎零延迟

#### 3.broker 配置
    可以用在broker 级别，用以控制所有主题的行为
    也可以用在主题级别，用于控制个别主题的行为。

主题级别控制可靠性，意味着集群可以同时拥有可靠和非可靠的主题。




##### 3.1复制系数
    主题级别：replication.factor
    broker级别：default.replication.factor

默认复制系数是3，即每个分区总共会被3个不同的broker复制3次。

建议把broker 分布在不同机架上，使用broker.rack 参数为每个broker配置所在机架的名字。

##### 3.2 不完全的首领选举
unclean.leader.election.enable 设为 true，表示允许不同步的副本成为首领。



##### 3.3最少同步副本
    在主题级别和broker级别上，参数为 min.insync.replicas
    对于3个副本，设置min.insync.replicas=2，至少要存在两个同步副本才能向分区写入数据。
    如果两个副本变为不可用，那么broker就会停止接受生产者的请求。
    尝试发送数据的生产者会收到NotEnoughReplicasException异常。
    消费者仍然可以继续读取已有的数据。


#### 4 在可靠的系统里使用生产者
    根据可靠性需求配置恰当的acks值
    在参数配置和代码里正确处理错误。

##### 4.1发送确认
    acks=0 生产者能够通过网络把消息发送出去，就认为消息已经成功写入Kafka。
    acks=1 首领在收到消息并把它写入到分区数据文件时会返回确认或错误响应。
    acks=all 首领在返回确认或错误响应之前，会等待所有同步副本都收到消息。和min.insync.replicas参数结合起来，就可以决定在返回确认前至少有多少个副本能够收到消息。

##### 4.2配置生产者的重试参数
    可重试错误：
        LEADER_NOT_AVALIABLE
    不可重试错误:
        INVALID_CONFIG
	
##### 4.3额外的错误处理
    不可重试的broker错误：消息大小错误、认证错误等
    在消息发送之前发送的错误：序列化错误
    在生产者达到重试次数上限时或者在消息占用的内存达到上限时发送的错误

编写消息错误处理器

	丢弃不合符的消息、记录错误、把消息存储在本地磁盘、回调另一个程序
	


#### 5. 在可靠的系统里使用消费者
##### 5.1消费者可靠性配置
    group.id 两个消费者具有相同的group.id ，并且订阅了同一个主题，则每个消费者会分到主题分区的一个子集。即只能读取所有消息的一个子集。（群组会读取主题的所有消息）
    如果你希望消费者可以看到主题的所有消息，那么需要为它们设置唯一的group.id


    auto.offset.reset 指定在没有偏移量可提交时，消费者会做什么。
    参数值：
    earliest  消费者会从分区的开始位置服务数据，可能读取重复数据
    latest 	  从分区末尾开始读取数据，可能错过消息
    enable.auto.commit  可以让消费者基于任务调度自动提交偏移量，也可以代码手动提交
            优点：可以少考虑一些问题
            缺点：无法控制重复处理消息，而且异步处理消息的话可能会在消息还没处理完毕就提交偏移量
    auto.commit.interval.ms 自动提交的频率，默认5s


##### 5.2显示提交偏移量
减少重复处理消息；把消息处理逻辑放在轮询之外。

    （1）总是在处理完事件之后再提交偏移量
    （2）提交频度是性能和重复消息数量之间的权衡
    （3）确保对提交的偏移量心里有数
            提交的偏移量可能是读取到的最新偏移量，而不是处理过的偏移量。
            需要处理完消息后再提交偏移量
    （4）再均衡
            一般要在分区被撤销之前提交偏移量，并在分配到新分区时清理之前的状态
    （5）消费者可能需要重试
            （5.1）提交最后一个处理成功的偏移量，然后把没处理的消息保存到缓冲区
            （5.2）把错误写入一个独立的主题，然后继续。一个独立的消费者群组负责从该主题读取错误消息，并进行重试
    （6）消费者可能需要维护状态
            KafkaStreams 类库，它为聚合、连接、时间窗、其他复杂分析提供了高级DSL API
    （7）长时间处理
            暂停的轮询时间不能超过几秒钟，这样客户端才能保持发送心跳。
            常见处理方式：使用线程池处理，暂停消费者，保持轮询，但不获取新数据，直到工作线程处理完成。
    （8）仅一次传递
            唯一键，消息本身包含唯一键，或者使用主题、分区和偏移量的组合来创建唯一键
            这个模式叫幂等性写入
            支持事务的数据库：把消息和偏移量放在同一个事务里，消费者启动时获取最近处理过的消息偏移量，然后调用seek()方法从该偏移量位置继续读取数据。



#### 6 验证系统可靠性
配置验证、应用程序验证、生产环境的应用程序监控

##### 6.1 配置验证
org.apache.kafka.tools包里的Verfiable Producer和VerifiableConsumer这两个工具类

##### 6.2应用程序验证
    故障测试：
    客户端从服务器断开连接
    首领选举
    依次重启broker
    依次重启消费者
    依次重启生产者

#### 6.3在生产环境监控可靠性
监控集群的监控状况、监控客户端和数据流

