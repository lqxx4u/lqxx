## 2.3broker配置
### 一、常规配置
#### 1.broker.id
broker标识符，默认为0，可以设置为任意正整数，集群唯一

#### 2.port
    hostname:port/path
    hostname:Zoopeeper服务器的机器名或IP地址
    Port是Zookeeper的客户端连接端口
    /path是可选的Zookeeper路径，作为Kafka集群的chroot 环境。如果不指定，默认使用根路径。如果指定的路径不存在，broker会在启动的时候创建它。

#### 4.log.dies 
Kafka消息保存在磁盘上，存放这些日志片段的目录是通过log.dirs指定的。

用一组逗号分隔的本地文件系统路径。指定了多个路径，broker会根据"最少使用"原则，把同一个分区的日志片段保存到同一个路径下。

注意：broker会往拥有最少数目分区的路径新增分区，而不是往拥有最小磁盘空间的路径新增分区。

#### 5.num.recovery.threads.per.data.dir
对于以下三种情况，使用可配置的线程池来处理日志片段：

    （1）服务器正常启动，用于打开每个分区的日志片段
    （2）服务器崩溃后重启，用于检查和截短每个分区的日志片段
    （3）服务器正常关闭，用于关闭日志片段

#### 6.auto.create.topics.enable
默认情况下，Kafka会在如下几种情形下自动创建主题：
当一个生产者开始往主题写入消息时
当一个消费者开始从主题读取消息时
当任意一个客户端向主题发送元数据请求时

### 二、主题的默认配置
#### 1.num.partitions
指定新创建的主题将包含多少个分区。默认为1.

注意：可以增加主题分区的个数，但是不能减少分区的个数。

Kafka集群通过分区对主题进行横向扩展

分区数量选择因素：

    主题需要达到多大的吞吐量
    估算单个分区写入数据的吞吐量
    每个broker包含的分区个数、可用的磁盘空间和网络带宽
    如果消息按不同的键来写入分区的，那么为已有的主题新增分区就会很困难
    单个broker对分区个数是有限制的，因为分区越多，占用的内存越多，完成首领选举需要的时间也越长。

知道吞吐量：分区个数= 主题吞吐量/消费者吞吐量

不知道吞吐量：限制分区大小在25g以内


#### 2.log.retention.ms
Kafka通常根据时间来决定数据可以保留多久。

默认使用log.retention.hours参数来配置时间，默认值为168小时（七天）

指定多个参数，优先使用具有最小值的那个参数

根据时间保留数据是通过检查磁盘上日志片段文件的最后修改时间来实现的。

一般来说，最后修改时间指的就是日志片段的关闭时间，也就是文件里最后一个消息的时间戳。

如果使用管理工具在服务器间移动分区，最后修改时间就不准确了。时间误差可能导致这些分区过多的保留数据。

#### 3.log.retention.bytes
通过保留的消息字节数来判断消息是否过期。

作用在每一个分区上。

同时指定了log.retention.bytes和log.retention.ms，只要任意一个条件得到满足，消息就会被删除。


#### 4.log.segment.bytes
以上设置都作用在日志片段上，而不是作用在单个消息上。

当消息达到broker时，它们被追加到分区的当前日志片段上。当日志片段大小达到log.segment.bytes指定的上限时，当前日志片段就会被关闭，一个新的日志片段被打开。如果一个日志片段被关闭，就开始等待过期。

使用时间戳获取偏移量：
>日志片段的大小会影响使用时间戳获取偏移量。Kafka会检查分区里最后修改时间大于指定时间戳的日志片段（已经被关闭的），该日志片段的前一个文件的最后修改时间小于指定时间戳。然后Kafka返回该日志片段（也就是文件名）开头的偏移量。对于使用时间戳获取偏移量的操作来说，日志片段越小，结果越准确。

#### 5.log.segment.ms
另一个控制日志片段关闭时间的参数，指定了多长时间之后日志片段会被关闭。

与log.segment.bytes同时存在不互斥。默认log.segment.ms没有设定值

基于时间的日志片段需要着重考虑并行关闭多个日志片段对磁盘性能的影响。

如果多个分区的日志片段永远不能达到大小的上限时发生。

#### 6.message.max.bytes
限制单个消息的大小，默认1 000 00，即1M。指的是压缩后的消息大小。

消费者客户端设置的fetch.message.max.bytes必须与服务器端设置的消息大小进行协调。如果这个值比message.max.bytes小，那么消费者就无法读取比较大的消息，导致出现消费者被阻塞的情况。


## 2.4硬件的选择
1.磁盘吞吐量

2.磁盘容量

3.内存

磁盘性能影响生产者

内存影响消费者。消费者一般从分区尾部读取消息，如果有生产者存在，就紧跟在生产者后面。这种情况下，消费者读取的消息会直接放在系统的页面缓存里，这比从磁盘上重新读取要快得多。

运行Kafka的JVM不需要太大的内存，剩余的系统内存可以用作页面缓存，或者用来缓存正在使用中的日志片段。因此不建议Kafka同其他重要应用程序部署在一起。

4.网络

网络吞吐量决定Kafka能够处理的最大数据流量。它和磁盘存储是制约Kafka扩展规模的主要因素。


5.CPU

客户端为了优化网络和磁盘空间，会对消息进行压缩。

服务器需要对消息进行批量解压，设置偏移量，然后重新进行批量压缩，再保存到磁盘上。这就是Kafka对计算处理能力有所要求的地方。

## 2.6Kafka集群
好处：跨服务器进行负载均衡、使用复制功能避免单点故障造成的数据丢失。

#### 1.需要多少个broker
>（1）需要多少磁盘空间保留数据，以及单个broker有多少空间可用。
>（2）集群处理请求的能力

#### 2.broker配置
把broker加入到集群：

    （1）所有broker都必须配置相同的zookeeper.connect，该参数指定了用于保存元数据的zookeeper群组和路径，
    （2）每个broker都必须为broker.id设置唯一的值。
两个broker值相同，第二个无法启动。

#### 3.操作系统调优
调优参数主要与虚拟内存、网络子系统和用来存储日志片段的磁盘挂载点有关。

（1）.虚拟内存
一般来说，Linux的虚拟内存会根据系统的工作负荷进行自动调整。我们可以对交换分区的处理方式和内存脏页进行调整，从而让Kafka更好的处理工作负载。
    
    尽量避免内存交换。vm.swapiness: 1
    调整内核对脏页的处理方式：vm.dirty_background_ratio: 5
    可以在/proc/vmstat文件里查看当前脏页数量： cat /proc/vmstat | grep "dirty|writeback"


（2）磁盘

主要影响因素：

（2.1）选择合适的磁盘硬件设备和使用RAID（磁盘阵列）

RAID技术主要有以下三个基本功能：

    (1)通过对磁盘上的数据进行条带化，实现对数据成块存取，减少磁盘的机械寻道时间，提高了数据存取速度。
    (2)通过对一个阵列中的几块磁盘同时读取，减少了磁盘的机械寻道时间，提高数据存取速度。 
    (3)通过镜像或者存储奇偶校验信息的方式，实现了对数据的冗余保护。
（2.2）文件系统：EXT4、XFS

XFS有比EXT4更安全的分配延迟算法

为kafka提供了更好的性能，文件系统自动调优。批量磁盘写入具有更高的效率，可以提升整体的I/O吞吐量

文件元数据包含三个时间戳：创建时间（ctime）、最后修改时间（mtime）、最后访问实际(atime)

为挂载点设置noatime 参数防止更新atime，不影响ctime和mtime。


（3）网络
针对快速的大流量网络传输进行优化

（1）对分配给socket读写缓冲区的内存大小作出调整，这样可以显著提升网络的传输性能。

socket读写缓冲区对应参数为：

net.core.wmem_default  合理值为 131 072 （128KB）

net.core.rmem_default

读写缓冲区最大值对应参数为：

net.core.wmem_max		合理值为 2097 152（2M）

net.core.rmem_max



（2）TCP socket

net.ipv4.tcp_wmem

net.ipv4.tcp.rmem


#### 2.7 生产环境的注意事项
2.7.1 垃圾回收器选项

MaxGCPauseMillis: 默认停顿时间

InitiatingHeapOccupancyPercent: G1启动新一轮垃圾回收之前可以使用的堆内存百分比，默认45



Kafka对堆内存使用率非常高，容易产生垃圾对象，可以把值设的小一些。





2.7.2 数据中心布局

不同机架、不同电源、不同网络



2.7.3 共享Zookeeper

Kafka使用Zookeeper来保存broker、主题和分区的元数据信息。



